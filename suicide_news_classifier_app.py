import streamlit as st
from requests_html import HTMLSession
from bs4 import BeautifulSoup
import asyncio
import nest_asyncio
import os, requests
import re
from bs4 import BeautifulSoup


# --------- ì´ë²¤íŠ¸ ë£¨í”„ ì¤€ë¹„ (requests_html .render() ì—ëŸ¬ ë°©ì§€) ---------
try:
    asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
nest_asyncio.apply()

# --------- ë‰´ìŠ¤ ë³¸ë¬¸ ì¶”ì¶œ ---------
def extract_news_text(url, max_retry=3):
    api_key = st.secrets["SCRAPINGANT_KEY"]
    api_url = (
        "https://api.scrapingant.com/v2/general?url="
        + requests.utils.quote(url)
        + f"&x-api-key={api_key}&browser=true&render_js=true"
    )
    for attempt in range(1, max_retry + 1):
        try:
            resp = requests.get(api_url, timeout=60)   # â† 60ì´ˆë¡œ ì¦ê°€
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")
            paragraphs = soup.find_all("p")
            text = "\n".join(
                p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)
            )
            return text or "âŒ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError):
            if attempt == max_retry:
                return "âŒ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: ScrapingAnt ì‘ë‹µ ì§€ì—°"
            time.sleep(2)  # 2ì´ˆ í›„ ì¬ì‹œë„
        except Exception as e:
            return f"âŒ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}"

# --------- ê¸°ì‚¬ ë“±ê¸‰ ë¶„ë¥˜ ---------
def normalize(text):
    # ìˆ«ìÂ·í•œê¸€Â·ì˜ë¬¸ë§Œ ë‚¨ê¸°ê³  ì „ë¶€ ì œê±° â†’ ê³µë°± í•˜ë‚˜ë¡œ
    cleaned = re.sub(r"[^0-9ê°€-í£a-zA-Z]", " ", text)
    return re.sub(r"\s+", " ", cleaned)
    
# â”€â”€â”€ ìƒˆ í•¨ìˆ˜ ì¶”ê°€ â”€â”€â”€
HELP_PATTERNS = [
    r"1393",
    r"1388",
    r"1577[-\s]?0199",
    r"1588[-\s]?9191",
    r"\b129\b"
]
def has_help_line(text: str) -> bool:
    for pat in HELP_PATTERNS:
        if re.search(pat, text):
            return True
    return False
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import re

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â‘  ë„ì›€ ê²½ë¡œ ì •ê·œì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HELP_PATTERNS = [
    r"1393",
    r"1388",
    r"1577[-\s]?0199",
    r"1588[-\s]?9191",
    r"\b129\b",
]

def has_help_line(text: str) -> bool:
    """1393Â·1388Â·1577-0199Â·1588-9191Â·129 ë“± â€˜í•«ë¼ì¸â€™ í‘œê¸° íƒì§€"""
    for pat in HELP_PATTERNS:
        if re.search(pat, text):
            return True
    return False
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def classify_article(text: str) -> str:
    werther_keywords = [
        "ê·¹ë‹¨ì  ì„ íƒ", "ëª©ìˆ¨ì„ ëŠ", "íˆ¬ì‹ ", "ë²ˆê°œíƒ„", "ìœ ì„œ", "ìŠ¤ìŠ¤ë¡œ ëª©ìˆ¨",
        "ì¶©ê²©", "ë¹„ê·¹", "ì‹œì‹ ", "ì‚¬ë§ ì›ì¸", "ë§ˆì•½ í˜ì˜", "ìœ ì„œ ì „ë¬¸"
    ]

    # â‘¡ ìœ„í—˜ ì ìˆ˜ : í‚¤ì›Œë“œê°€ ëª‡ ê°œ ë“¤ì–´ ìˆëŠ”ê°€
    risk_score = sum(k in text for k in werther_keywords)

    # â‘¢ ì•ˆì „ ì ìˆ˜ : í•«ë¼ì¸ í•˜ë‚˜ë¼ë„ ë°œê²¬ë˜ë©´ 1
    safe_score = 1 if has_help_line(text) else 0

    # â‘£ ë¶„ë¥˜ ê·œì¹™ (ë„ì›€ ë²ˆí˜¸ í•˜ë‚˜ë§Œ ìˆì–´ë„ â€˜ê¶Œì¥â€™ìœ¼ë¡œ ì¸ì •)
    if safe_score >= 1:            # ë„ì›€ ê²½ë¡œ(í•«ë¼ì¸)ë§Œ ìˆìœ¼ë©´ 'ê¶Œì¥'
        return "ê¶Œì¥"
    elif risk_score >= 2:          # ìœ„í—˜ í‚¤ì›Œë“œ ë‹¤ìˆ˜ â€†â€Š+â€Š ë„ì›€ ì—†ìŒ
        return "ìœ„í—˜"
    else:                          # ê·¸ ë°–ì€ ì¤‘ë¦½
        return "ì¤‘ë¦½"

# --------- ë“±ê¸‰ë³„ ê°€ì´ë“œë¼ì¸ ---------
def guideline(label):
    if label == "ìœ„í—˜":
        return """âš ï¸ **ìœ„í—˜(ë² ë¥´í…Œë¥´í˜•)**  
- ë°©ë²•Â·ë„êµ¬Â·ì¥ì†ŒÂ·ìœ ì„œ ë‚´ìš© ì–¸ê¸‰  
- ìê·¹ì Â·ì„ ì •ì  í—¤ë“œë¼ì¸  
- ì‚¬ê±´ ì›ì¸ ë‹¨ìˆœ ê·€ì†(ê°œì¸ ì±…ì„ í”„ë ˆì„)  
- ë„ì›€ ê²½ë¡œ(1393, 1388 ë“±) ëˆ„ë½  
**â†’ ìì‚´ ë³´ë„ ì¤€ì¹™ 4.0ì— ë”°ë¼ ì „ë©´ ìˆ˜ì • í•„ìš”**"""
    elif label == "ì¤‘ë¦½":
        return """â„¹ï¸ **ì¤‘ë¦½**  
- ë³´ë„ ì¤€ì¹™ ëŒ€ì²´ë¡œ ì¤€ìˆ˜í•˜ë‚˜ íšŒë³µ ì„œì‚¬Â·ì˜ˆë°© ì •ë³´ ë¶€ì¡±  
- ë°©ë²•Â·ì¥ì†ŒÂ·ìœ ì„œ ë¹„ê³µê°œ, ê·¸ëŸ¬ë‚˜ ë„ì›€ ê²½ë¡œ ì—†ìŒ  
- êµ¬ì¡°ì  ì›ì¸Â·ì •ì±… ëŒ€ì•ˆ ë¶€ì¡±  
**â†’ ë„ì›€ ê²½ë¡œì™€ íšŒë³µ ì„œì‚¬ ì¶”ê°€ í•„ìš”**"""
    elif label == "ê¶Œì¥":
        return """âœ… **ê¶Œì¥(íŒŒíŒŒê²Œë…¸í˜•)**  
- ë°©ë²•Â·ë„êµ¬Â·ì¥ì†ŒÂ·ìœ ì„œ ë‚´ìš© ì „ë©´ ë¹„ê³µê°œ  
- ì¤‘ë¦½ì Â·ì‚¬ì‹¤ì  í‘œí˜„ ì‚¬ìš©  
- íšŒë³µ ì‚¬ë¡€Â·êµ¬ì¡°ì  ì›ì¸ ì œì‹œ  
- ë„ì›€ ê²½ë¡œ(1393, 1577-0199, 1388 ë“±) í•„ìˆ˜ ì‚½ì…  
**â†’ ì˜ˆë°© íš¨ê³¼ê°€ ë†’ì€ ëª¨ë²” ë³´ë„ ì‚¬ë¡€**"""
    return ""

# --------- Streamlit UI ---------
if "article_text" not in st.session_state:
    st.session_state.article_text = ""

st.title("ğŸ“° ìì‚´ ê´€ë ¨ ê¸°ì‚¬ ìë™ ë“±ê¸‰ íŒë³„ê¸° ")

st.session_state.article_text = st.text_area("ê¸°ì‚¬ ë³¸ë¬¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:")

# í˜„ì¬ ê¸°ì‚¬ ë³¸ë¬¸ í‘œì‹œ (ì›í•˜ë©´ ìƒëµ ê°€ëŠ¥)
if st.session_state.article_text:
    st.text_area("ê¸°ì‚¬ ë³¸ë¬¸", st.session_state.article_text, height=200, disabled=True)

# ë“±ê¸‰ íŒë³„ ë²„íŠ¼
if st.button("ë“±ê¸‰ íŒë³„"):
    if st.session_state.article_text.strip():
        label = classify_article(st.session_state.article_text)
        st.subheader(f"ë“±ê¸‰: {label}")
        st.markdown(guideline(label))
    else:
        st.warning("ê¸°ì‚¬ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")










